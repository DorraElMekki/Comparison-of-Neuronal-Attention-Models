{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59647,
     "status": "ok",
     "timestamp": 1560157066995,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "OP9NqzeWnn7h",
    "outputId": "7d9c8b5a-ea31-4e99-9fb6-7a30d9f9cd7a"
   },
   "source": [
    "# Neuronal Attention model \n",
    "\n",
    "## Visualisation using Tensor-board\n",
    "Enter this command \n",
    "tensorboard --logdir logs/100x100-4glimpse-12x12-4scales-128batch-100epochs\n",
    "or this one\n",
    "tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59631,
     "status": "ok",
     "timestamp": 1560157066999,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "dY0TBzdLlHJh",
    "outputId": "12158ef8-f69d-4715-89eb-bd13efbb47a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python 3!\n",
      "/device:GPU:0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2400627669966820159\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4945621811\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5626239723515773655\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Using Python {}!'.format(sys.version_info[0]))\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name() )\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "\n",
    "print(local_device_protos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63052,
     "status": "ok",
     "timestamp": 1560157070434,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "PrQr-uLiirca",
    "outputId": "104a775e-35ca-4de0-a148-dab1b6d39133"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Recurrent Models of Visual Attention V. Mnih et al.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "try:\n",
    "  xrange\n",
    "except NameError:\n",
    "  xrange=range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oadcenFJIHAt"
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "\n",
    "  win_size = 12 ## kim: glimse sensor  ~~\n",
    "  num_glimpses = 4 ## of gimpse per image\n",
    "  num_scales = 4 ##\n",
    "\n",
    "  batch_size = 256 # 128 ##\n",
    "  eval_batch_size = batch_size #128 ##\n",
    "\n",
    "\n",
    "  step = 100 ## this is the nb of epoch\n",
    "    \n",
    "  #AdamOptimizer is configured somewhere else\n",
    "\n",
    "  lr_start = 1e-3\n",
    "  lr_min = 1e-4\n",
    "  decay = 0.97  \n",
    "  \n",
    "  #less important config  \n",
    "  loc_std = 0.22\n",
    "  original_size = 100 ##\n",
    "  num_channels = 1 # do not change, not tested\n",
    "  bandwidth = win_size**2\n",
    "  sensor_size = win_size**2 * num_channels * num_scales\n",
    "  minRadius = 8\n",
    "  hg_size = hl_size = 128\n",
    "  g_size = 256\n",
    "  cell_output_size = 256\n",
    "  loc_dim = 2\n",
    "  cell_size = 256\n",
    "  cell_out_size = cell_size\n",
    "  num_classes = 10\n",
    "  max_grad_norm = 5.\n",
    "\n",
    "  # Monte Carlo sampling\n",
    "  M = 10\n",
    "\n",
    "  # Run name\n",
    "  run_name = \"{}x{}-{}glimpse-{}x{}-{}scales-{}batch-{}epochs\".format(original_size,\n",
    "                                                     original_size,\n",
    "                                                     num_glimpses,\n",
    "                                                     win_size,\n",
    "                                                     win_size,\n",
    "                                                     num_scales,\n",
    "                                                     batch_size,\n",
    "                                                     step\n",
    "                                                    )\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63044,
     "status": "ok",
     "timestamp": 1560157070437,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "d7hmXcp8nn7u",
    "outputId": "87752855-1c25-4d9e-e0f6-881d6fce6c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created:\n",
      "run-100x100-4glimpse-12x12-4scales-256batch-100epochs.log\n",
      "./logs/100x100-4glimpse-12x12-4scales-256batch-100epochs\n",
      "model-100x100-4glimpse-12x12-4scales-256batch-100epochs.ckpt\n"
     ]
    }
   ],
   "source": [
    "#File Created\n",
    "basicConfigFileName = 'run-{}.log'.format(config.run_name)\n",
    "tfLogFile = \"./logs/\"+config.run_name\n",
    "savedModel_path =  \"model-{}.ckpt\".format(config.run_name)\n",
    "print(\"File created:\")\n",
    "print(basicConfigFileName)\n",
    "print(tfLogFile)\n",
    "print(savedModel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 77168,
     "status": "ok",
     "timestamp": 1560157084569,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "rXnNsyRKIGdq",
    "outputId": "deb4be11-e063-4d12-863f-cb6bdc1f5606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (54000, 10000)\n",
      "54000 train samples\n",
      "6000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(filename= basicConfigFileName,level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "rnn_cell = tf.nn.rnn_cell\n",
    "seq2seq = tf.contrib.legacy_seq2seq\n",
    "\n",
    "#mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "data = np.load('../data/mnist_digit_sample_8dsistortions9x9.npz')\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "x_train = np.reshape(data['X_train'], (-1, 10000))\n",
    "y_train = np.reshape(data['y_train'], (-1))\n",
    "x_va = np.reshape(data['X_valid'], (-1, 10000))\n",
    "y_va = np.reshape(data['y_valid'], (-1))\n",
    "x_test = np.reshape(data['X_test'], (-1, 10000))\n",
    "y_test = np.reshape(data['y_test'], (-1))\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_va.shape[0], 'validation samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NP7RbmZdmTYx"
   },
   "outputs": [],
   "source": [
    "input_shape = (config.original_size, config.original_size, 1)\n",
    "\n",
    "num_epochs = config.step\n",
    "\n",
    "loc_mean_arr = []\n",
    "sampled_loc_arr = []\n",
    "\n",
    "def get_next_input(output, i):\n",
    "  loc, loc_mean = loc_net(output)\n",
    "  gl_next = gl(loc)\n",
    "  loc_mean_arr.append(loc_mean)\n",
    "  sampled_loc_arr.append(loc)\n",
    "  return gl_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVANDfcY6sNt"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "distributions = tf.contrib.distributions\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.0, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def loglikelihood(mean_arr, sampled_arr, sigma):\n",
    "  mu = tf.stack(mean_arr)  # mu = [timesteps, batch_sz, loc_dim]\n",
    "  sampled = tf.stack(sampled_arr)  # same shape as mu\n",
    "  gaussian = distributions.Normal(mu, sigma)\n",
    "  logll = gaussian.log_prob(sampled)  # [timesteps, batch_sz, loc_dim]\n",
    "  logll = tf.reduce_sum(logll, 2)\n",
    "  logll = tf.transpose(logll)  # [batch_sz, timesteps]\n",
    "  return logll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyTEfjE63M6H"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class GlimpseNet(object):\n",
    "  \"\"\"Glimpse network.\n",
    "\n",
    "  Take glimpse location input and output features for RNN.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config, images_ph):\n",
    "    self.original_size = config.original_size\n",
    "    self.num_channels = config.num_channels\n",
    "    self.sensor_size = config.sensor_size\n",
    "    self.win_size = config.win_size\n",
    "    self.minRadius = config.minRadius\n",
    "    self.num_scales = config.num_scales\n",
    "\n",
    "    self.hg_size = config.hg_size\n",
    "    self.hl_size = config.hl_size\n",
    "    self.g_size = config.g_size\n",
    "    self.loc_dim = config.loc_dim\n",
    "\n",
    "    self.images_ph = images_ph\n",
    "\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    \"\"\" Initialize all the trainable weights.\"\"\"\n",
    "    self.w_g0 = weight_variable((self.sensor_size, self.hg_size))\n",
    "    self.b_g0 = bias_variable((self.hg_size,))\n",
    "    self.w_l0 = weight_variable((self.loc_dim, self.hl_size))\n",
    "    self.b_l0 = bias_variable((self.hl_size,))\n",
    "    self.w_g1 = weight_variable((self.hg_size, self.g_size))\n",
    "    self.b_g1 = bias_variable((self.g_size,))\n",
    "    self.w_l1 = weight_variable((self.hl_size, self.g_size))\n",
    "    self.b_l1 = weight_variable((self.g_size,))\n",
    "\n",
    "  def get_glimpse(self, loc):\n",
    "    \"\"\"Take glimpse on the original images.\n",
    "\n",
    "    :param loc: 2D tuple locations, values between [-1.0, 1.0]\n",
    "    :return: glimpse vector\n",
    "    \"\"\"\n",
    "    imgs = tf.reshape(self.images_ph, [\n",
    "        tf.shape(self.images_ph)[0], self.original_size, self.original_size,\n",
    "        self.num_channels\n",
    "    ])\n",
    "\n",
    "    glimpse_all_scales = []\n",
    "    for scale in range(1, self.num_scales + 1):\n",
    "      glimpse_imgs = tf.image.extract_glimpse(imgs,\n",
    "                                              [self.win_size * scale, self.win_size * scale], loc) # BHWC\n",
    "\n",
    "      glimpse_imgs = tf.image.resize_bilinear(glimpse_imgs, (self.win_size, self.win_size)) # BHWC\n",
    "      glimpse_imgs = tf.reshape(glimpse_imgs, [\n",
    "          tf.shape(loc)[0], self.win_size * self.win_size * self.num_channels\n",
    "      ]) #(B, H * W * C)\n",
    "\n",
    "      glimpse_all_scales.append(glimpse_imgs)\n",
    "\n",
    "    return tf.stack(glimpse_all_scales, axis=1) # (B, H * W * C * S)\n",
    "\n",
    "  def __call__(self, loc):\n",
    "    glimpse_input = self.get_glimpse(loc) # (B, H * W * C * S)\n",
    "    glimpse_input = tf.reshape(glimpse_input,\n",
    "                               (tf.shape(loc)[0], self.sensor_size))\n",
    "    g = tf.nn.relu(tf.nn.xw_plus_b(glimpse_input, self.w_g0, self.b_g0))\n",
    "    g = tf.nn.xw_plus_b(g, self.w_g1, self.b_g1)\n",
    "    l = tf.nn.relu(tf.nn.xw_plus_b(loc, self.w_l0, self.b_l0))\n",
    "    l = tf.nn.xw_plus_b(l, self.w_l1, self.b_l1)\n",
    "    g = tf.nn.relu(g + l)\n",
    "    return g\n",
    "\n",
    "\n",
    "class LocNet(object):\n",
    "  \"\"\"Location network.\n",
    "\n",
    "  Take output from other network and produce and sample the next location.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config):\n",
    "    self.loc_dim = config.loc_dim\n",
    "    self.input_dim = config.cell_output_size\n",
    "    self.loc_std = config.loc_std\n",
    "    self._sampling = True\n",
    "\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    self.w = weight_variable((self.input_dim, self.loc_dim))\n",
    "    self.b = bias_variable((self.loc_dim,))\n",
    "\n",
    "  def __call__(self, input):\n",
    "    mean = tf.clip_by_value(tf.nn.xw_plus_b(input, self.w, self.b), -1., 1.)\n",
    "    mean = tf.stop_gradient(mean)\n",
    "    if self._sampling:\n",
    "      loc = mean + tf.random_normal(\n",
    "          (tf.shape(input)[0], self.loc_dim), stddev=self.loc_std)\n",
    "      loc = tf.clip_by_value(loc, -1., 1.)\n",
    "    else:\n",
    "      loc = mean\n",
    "    loc = tf.stop_gradient(loc)\n",
    "    return loc, mean\n",
    "\n",
    "  @property\n",
    "  def sampling(self):\n",
    "    return self._sampling\n",
    "\n",
    "  @sampling.setter\n",
    "  def sampling(self, sampling):\n",
    "    self._sampling = sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79259,
     "status": "ok",
     "timestamp": 1560157086673,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "y6qr4Ghmm57I",
    "outputId": "9f4b6b01-887a-4b8c-83d1-1039a387a3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensor-env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-10-4d4b78dab349>:25: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-ff39f6e7cf00>:23: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensor-env\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensor-env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#import glimpse.py\n",
    "# placeholders\n",
    "images_ph = tf.placeholder(tf.float32,\n",
    "                           [None, config.original_size * config.original_size *\n",
    "                            config.num_channels])\n",
    "labels_ph = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# Monte Carlo sampling, duplicate M times, see Eqn (2)\n",
    "images_expanded = tf.tile(images_ph, [config.M, 1])\n",
    "labels_expanded = tf.tile(labels_ph, [config.M])\n",
    "\n",
    "# Build the aux nets.\n",
    "with tf.variable_scope('glimpse_net'):\n",
    "  # gl = GlimpseNet(config, images_ph)\n",
    "  gl = GlimpseNet(config, images_expanded)\n",
    "with tf.variable_scope('loc_net'):\n",
    "  loc_net = LocNet(config)\n",
    "\n",
    "# number of examples\n",
    "# N = tf.shape(images_ph)[0]\n",
    "N = tf.shape(images_expanded)[0]\n",
    "init_loc = tf.random_uniform((N, 2), minval=-1, maxval=1)\n",
    "init_glimpse = gl(init_loc)\n",
    "# Core network.\n",
    "lstm_cell = rnn_cell.LSTMCell(config.cell_size, state_is_tuple=True)\n",
    "init_state = lstm_cell.zero_state(N, tf.float32)\n",
    "inputs = [init_glimpse]\n",
    "inputs.extend([0] * (config.num_glimpses))\n",
    "outputs, _ = seq2seq.rnn_decoder(\n",
    "    inputs, init_state, lstm_cell, loop_function=get_next_input)\n",
    "\n",
    "# Time independent baselines\n",
    "with tf.variable_scope('baseline'):\n",
    "  w_baseline = weight_variable((config.cell_output_size, 1))\n",
    "  b_baseline = bias_variable((1,))\n",
    "baselines = []\n",
    "for t, output in enumerate(outputs[1:]):\n",
    "  baseline_t = tf.nn.xw_plus_b(output, w_baseline, b_baseline)\n",
    "  baseline_t = tf.squeeze(baseline_t)\n",
    "  baselines.append(baseline_t)\n",
    "baselines = tf.stack(baselines)  # [timesteps, batch_sz]\n",
    "baselines = tf.transpose(baselines)  # [batch_sz, timesteps]\n",
    "\n",
    "# Take the last step only.\n",
    "output = outputs[-1]\n",
    "# Build classification network.\n",
    "with tf.variable_scope('cls'):\n",
    "  w_logit = weight_variable((config.cell_output_size, config.num_classes))\n",
    "  b_logit = bias_variable((config.num_classes,))\n",
    "logits = tf.nn.xw_plus_b(output, w_logit, b_logit)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "correct_prediction = tf.equal(tf.argmax(softmax,1), labels_expanded)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# average statistics after Monte Carlo sampling \"M\"\n",
    "avg_softmax = tf.reshape(softmax, [config.M, -1, config.num_classes])\n",
    "avg_softmax = tf.reduce_mean(avg_softmax, axis=0) # (B, num_classes)\n",
    "avg_y_pred = tf.argmax(avg_softmax, axis=1) #(B, )\n",
    "avg_acc = tf.reduce_mean(tf.cast(tf.equal(avg_y_pred, labels_ph), tf.float32))\n",
    "\n",
    "# cross-entropy.\n",
    "xent = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels_expanded)\n",
    "xent = tf.reduce_mean(xent)\n",
    "\n",
    "# 0/1 reward.\n",
    "y_pred = tf.argmax(logits, 1)\n",
    "reward = tf.cast(tf.equal(y_pred, labels_expanded), tf.float32)\n",
    "rewards = tf.expand_dims(reward, 1)  # [batch_sz, 1]\n",
    "rewards = tf.tile(rewards, (1, config.num_glimpses))  # [batch_sz, timesteps]\n",
    "logll = loglikelihood(loc_mean_arr, sampled_loc_arr, config.loc_std)\n",
    "advs = rewards - tf.stop_gradient(baselines)\n",
    "logllratio = tf.reduce_mean(logll * advs)\n",
    "reward = tf.reduce_mean(reward)\n",
    "\n",
    "baselines_mse = tf.reduce_mean(tf.square((rewards - baselines)))\n",
    "var_list = tf.trainable_variables()\n",
    "\n",
    "# hybrid loss\n",
    "loss = -logllratio + xent + baselines_mse  # `-` for minimize\n",
    "grads = tf.gradients(loss, var_list)\n",
    "grads, _ = tf.clip_by_global_norm(grads, config.max_grad_norm)\n",
    "\n",
    "# learning rate\n",
    "global_step = tf.get_variable(\n",
    "    'global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "training_steps_per_epoch = x_train.shape[0] // config.batch_size\n",
    "starter_learning_rate = config.lr_start\n",
    "# decay per training epoch\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    starter_learning_rate,\n",
    "    global_step,\n",
    "    training_steps_per_epoch,\n",
    "    config.decay,\n",
    "    staircase=True)\n",
    "learning_rate = tf.maximum(learning_rate, config.lr_min)\n",
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = opt.apply_gradients(zip(grads, var_list), global_step=global_step)\n",
    "\n",
    "# tensorboard logging\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "tf.summary.scalar(\"reward\", reward)\n",
    "tf.summary.scalar(\"xent\", xent)\n",
    "tf.summary.scalar(\"baselines_mse\", baselines_mse)\n",
    "tf.summary.scalar(\"logllratio\", logllratio)\n",
    "tf.summary.scalar(\"avg_accuracy\", avg_acc)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTgt2N39nn7_"
   },
   "outputs": [],
   "source": [
    "# stats\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 217772,
     "status": "ok",
     "timestamp": 1560157225194,
     "user": {
      "displayName": "sephiros sama",
      "photoUrl": "https://lh5.googleusercontent.com/-Aaghu78j1FA/AAAAAAAAAAI/AAAAAAAAImI/of29pyh0eh4/s64/photo.jpg",
      "userId": "04364851670955414673"
     },
     "user_tz": -120
    },
    "id": "phcl3M-0KE0z",
    "outputId": "3000573c-6820-4ab6-d801-a240dcc28432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensor-env\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "num_epochs:  0\n",
      "time_per_epoch:  43.8110625743866\n",
      "time left:  1:13:01.106257\n",
      "num_epochs:  1\n",
      "time_per_epoch:  42.51531219482422\n",
      "time left:  1:11:13.155551\n",
      "num_epochs:  2\n",
      "time_per_epoch:  42.76786756515503\n",
      "time left:  1:10:17.111169\n",
      "num_epochs:  3\n",
      "time_per_epoch:  44.9837441444397\n",
      "time left:  1:10:21.415363\n",
      "num_epochs:  4\n",
      "time_per_epoch:  43.57057166099548\n",
      "time left:  1:09:38.890627\n",
      "num_epochs:  5\n",
      "time_per_epoch:  43.03393769264221\n",
      "time left:  1:08:47.520230\n",
      "num_epochs:  6\n",
      "time_per_epoch:  43.233421087265015\n",
      "time left:  1:08:01.196782\n",
      "num_epochs:  7\n",
      "time_per_epoch:  44.02527475357056\n",
      "time left:  1:07:24.874338\n",
      "num_epochs:  8\n",
      "time_per_epoch:  43.946797609329224\n",
      "time left:  1:06:46.017101\n",
      "num_epochs:  9\n",
      "time_per_epoch:  45.61204385757446\n",
      "time left:  1:06:21.295692\n",
      "num_epochs:  10\n",
      "time_per_epoch:  42.81254744529724\n",
      "time left:  1:05:29.871015\n",
      "num_epochs:  11\n",
      "time_per_epoch:  42.71181631088257\n",
      "time left:  1:04:39.134604\n",
      "num_epochs:  12\n",
      "time_per_epoch:  42.52631378173828\n",
      "time left:  1:03:48.383794\n",
      "num_epochs:  13\n",
      "time_per_epoch:  43.359087228775024\n",
      "time left:  1:03:03.982852\n",
      "num_epochs:  14\n",
      "time_per_epoch:  42.55722904205322\n",
      "time left:  1:02:15.117656\n",
      "num_epochs:  15\n",
      "time_per_epoch:  42.552297830581665\n",
      "time left:  1:01:27.014759\n",
      "num_epochs:  16\n",
      "time_per_epoch:  43.205475091934204\n",
      "time left:  1:00:42.792338\n",
      "num_epochs:  17\n",
      "time_per_epoch:  42.5243182182312\n",
      "time left:  0:59:55.542021\n",
      "num_epochs:  18\n",
      "time_per_epoch:  42.54423379898071\n",
      "time left:  0:59:08.875129\n",
      "num_epochs:  19\n",
      "time_per_epoch:  42.59117102622986\n",
      "time left:  0:58:22.814646\n",
      "num_epochs:  20\n",
      "time_per_epoch:  42.606215715408325\n",
      "time left:  0:57:37.141659\n",
      "num_epochs:  21\n",
      "time_per_epoch:  42.460556983947754\n",
      "time left:  0:56:51.224453\n",
      "num_epochs:  22\n",
      "time_per_epoch:  42.68391180038452\n",
      "time left:  0:56:06.361819\n",
      "num_epochs:  23\n",
      "time_per_epoch:  42.691890001297\n",
      "time left:  0:55:21.709483\n",
      "num_epochs:  24\n",
      "time_per_epoch:  42.63496971130371\n",
      "time left:  0:54:37.040924\n",
      "num_epochs:  25\n",
      "time_per_epoch:  42.644996643066406\n",
      "time left:  0:53:52.554764\n",
      "num_epochs:  26\n",
      "time_per_epoch:  42.508360385894775\n",
      "time left:  0:53:07.830501\n",
      "num_epochs:  27\n",
      "time_per_epoch:  43.348116874694824\n",
      "time left:  0:52:25.453883\n",
      "num_epochs:  28\n",
      "time_per_epoch:  42.862412214279175\n",
      "time left:  0:51:41.806857\n",
      "num_epochs:  29\n",
      "time_per_epoch:  42.91626954078674\n",
      "time left:  0:50:58.337171\n",
      "num_epochs:  30\n",
      "time_per_epoch:  43.30227017402649\n",
      "time left:  0:50:15.777061\n",
      "num_epochs:  31\n",
      "time_per_epoch:  42.992067098617554\n",
      "time left:  0:49:32.499472\n",
      "num_epochs:  32\n",
      "time_per_epoch:  43.865700244903564\n",
      "time left:  0:48:51.039401\n",
      "num_epochs:  33\n",
      "time_per_epoch:  43.50971484184265\n",
      "time left:  0:48:08.738293\n",
      "num_epochs:  34\n",
      "time_per_epoch:  42.81251502037048\n",
      "time left:  0:47:25.051459\n",
      "num_epochs:  35\n",
      "time_per_epoch:  42.88338828086853\n",
      "time left:  0:46:41.541163\n",
      "num_epochs:  36\n",
      "time_per_epoch:  43.024980306625366\n",
      "time left:  0:45:58.309671\n",
      "num_epochs:  37\n",
      "time_per_epoch:  42.73276376724243\n",
      "time left:  0:45:14.604583\n",
      "num_epochs:  38\n",
      "time_per_epoch:  42.914278745651245\n",
      "time left:  0:44:31.237921\n",
      "num_epochs:  39\n",
      "time_per_epoch:  43.05988168716431\n",
      "time left:  0:43:48.115922\n",
      "num_epochs:  40\n",
      "time_per_epoch:  42.86341309547424\n",
      "time left:  0:43:04.709438\n",
      "num_epochs:  41\n",
      "time_per_epoch:  43.66824531555176\n",
      "time left:  0:42:22.459412\n",
      "num_epochs:  42\n",
      "time_per_epoch:  43.59847855567932\n",
      "time left:  0:41:40.050621\n",
      "num_epochs:  43\n",
      "time_per_epoch:  43.581522941589355\n",
      "time left:  0:40:57.565786\n",
      "num_epochs:  44\n",
      "time_per_epoch:  44.11503529548645\n",
      "time left:  0:40:15.694849\n",
      "num_epochs:  45\n",
      "time_per_epoch:  46.14563608169556\n",
      "time left:  0:39:36.155430\n",
      "num_epochs:  46\n",
      "time_per_epoch:  47.41980528831482\n",
      "time left:  0:38:57.798790\n",
      "num_epochs:  47\n",
      "time_per_epoch:  47.10210204124451\n",
      "time left:  0:38:18.712578\n",
      "num_epochs:  48\n",
      "time_per_epoch:  46.02490568161011\n",
      "time left:  0:37:38.156039\n",
      "num_epochs:  49\n",
      "time_per_epoch:  43.76300597190857\n",
      "time left:  0:36:55.073629\n",
      "num_epochs:  50\n",
      "time_per_epoch:  43.37105584144592\n",
      "time left:  0:36:11.580263\n",
      "num_epochs:  51\n",
      "time_per_epoch:  43.37703895568848\n",
      "time left:  0:35:28.097239\n",
      "num_epochs:  52\n",
      "time_per_epoch:  43.21849298477173\n",
      "time left:  0:34:44.475503\n",
      "num_epochs:  53\n",
      "time_per_epoch:  43.802961587905884\n",
      "time left:  0:34:01.377389\n",
      "num_epochs:  54\n",
      "time_per_epoch:  43.05783700942993\n",
      "time left:  0:33:17.629585\n",
      "num_epochs:  55\n",
      "time_per_epoch:  43.180596113204956\n",
      "time left:  0:32:34.005068\n",
      "num_epochs:  56\n",
      "time_per_epoch:  42.71281337738037\n",
      "time left:  0:31:50.035779\n",
      "num_epochs:  57\n",
      "time_per_epoch:  43.03498911857605\n",
      "time left:  0:31:06.348657\n",
      "num_epochs:  58\n",
      "time_per_epoch:  43.297221422195435\n",
      "time left:  0:30:22.870284\n",
      "num_epochs:  59\n",
      "time_per_epoch:  42.8853542804718\n",
      "time left:  0:29:39.115792\n",
      "num_epochs:  60\n",
      "time_per_epoch:  43.078835248947144\n",
      "time left:  0:28:55.516670\n",
      "num_epochs:  61\n",
      "time_per_epoch:  42.844497203826904\n",
      "time left:  0:28:11.787542\n",
      "num_epochs:  62\n",
      "time_per_epoch:  42.9641592502594\n",
      "time left:  0:27:28.158051\n",
      "num_epochs:  63\n",
      "time_per_epoch:  42.590142250061035\n",
      "time left:  0:26:44.333681\n",
      "num_epochs:  64\n",
      "time_per_epoch:  42.51334619522095\n",
      "time left:  0:26:00.504762\n",
      "num_epochs:  65\n",
      "time_per_epoch:  42.4684681892395\n",
      "time left:  0:25:16.691842\n",
      "num_epochs:  66\n",
      "time_per_epoch:  43.585506200790405\n",
      "time left:  0:24:33.485393\n",
      "num_epochs:  67\n",
      "time_per_epoch:  43.20350885391235\n",
      "time left:  0:23:50.082899\n",
      "num_epochs:  68\n",
      "time_per_epoch:  42.50038385391235\n",
      "time left:  0:23:06.360054\n",
      "num_epochs:  69\n",
      "time_per_epoch:  42.62703800201416\n",
      "time left:  0:22:22.728630\n",
      "num_epochs:  70\n",
      "time_per_epoch:  42.42259168624878\n",
      "time left:  0:21:39.038225\n",
      "num_epochs:  71\n",
      "time_per_epoch:  42.66191649436951\n",
      "time left:  0:20:55.479847\n",
      "num_epochs:  72\n",
      "time_per_epoch:  42.863410234451294\n",
      "time left:  0:20:12.023286\n",
      "num_epochs:  73\n",
      "time_per_epoch:  42.91331100463867\n",
      "time left:  0:19:28.600912\n",
      "num_epochs:  74\n",
      "time_per_epoch:  42.64699673652649\n",
      "time left:  0:18:45.099774\n",
      "num_epochs:  75\n",
      "time_per_epoch:  42.57817602157593\n",
      "time left:  0:18:01.598778\n",
      "num_epochs:  76\n",
      "time_per_epoch:  42.39762544631958\n",
      "time left:  0:17:18.065114\n",
      "num_epochs:  77\n",
      "time_per_epoch:  42.538283824920654\n",
      "time left:  0:16:34.602039\n",
      "num_epochs:  78\n",
      "time_per_epoch:  42.46247577667236\n",
      "time left:  0:15:51.140953\n",
      "num_epochs:  79\n",
      "time_per_epoch:  42.582138538360596\n",
      "time left:  0:15:07.736244\n",
      "num_epochs:  80\n",
      "time_per_epoch:  42.81055402755737\n",
      "time left:  0:14:24.408244\n",
      "num_epochs:  81\n",
      "time_per_epoch:  42.69885206222534\n",
      "time left:  0:13:41.066982\n",
      "num_epochs:  82\n",
      "time_per_epoch:  42.615129232406616\n",
      "time left:  0:12:57.723044\n",
      "num_epochs:  83\n",
      "time_per_epoch:  42.58413529396057\n",
      "time left:  0:12:14.390185\n",
      "num_epochs:  84\n",
      "time_per_epoch:  42.593104124069214\n",
      "time left:  0:11:31.076632\n",
      "num_epochs:  85\n",
      "time_per_epoch:  42.68585157394409\n",
      "time left:  0:10:47.796190\n",
      "num_epochs:  86\n",
      "time_per_epoch:  43.0290048122406\n",
      "time left:  0:10:04.584763\n",
      "num_epochs:  87\n",
      "time_per_epoch:  46.319011926651\n",
      "time left:  0:09:21.863171\n",
      "num_epochs:  88\n",
      "time_per_epoch:  46.814696073532104\n",
      "time left:  0:08:39.127707\n",
      "num_epochs:  89\n",
      "time_per_epoch:  45.36932945251465\n",
      "time left:  0:07:56.125031\n",
      "num_epochs:  90\n",
      "time_per_epoch:  44.59899926185608\n",
      "time left:  0:07:12.985432\n",
      "num_epochs:  91\n",
      "time_per_epoch:  44.696080684661865\n",
      "time left:  0:06:29.823604\n",
      "num_epochs:  92\n",
      "time_per_epoch:  44.21268153190613\n",
      "time left:  0:05:46.587284\n",
      "num_epochs:  93\n",
      "time_per_epoch:  43.61506628990173\n",
      "time left:  0:05:03.285592\n",
      "num_epochs:  94\n",
      "time_per_epoch:  44.23203468322754\n",
      "time left:  0:04:20.016270\n",
      "num_epochs:  95\n",
      "time_per_epoch:  44.37371325492859\n",
      "time left:  0:03:36.734322\n",
      "num_epochs:  96\n",
      "time_per_epoch:  44.87767481803894\n",
      "time left:  0:02:53.450625\n",
      "num_epochs:  97\n",
      "time_per_epoch:  45.68118977546692\n",
      "time left:  0:02:10.158944\n",
      "num_epochs:  98\n",
      "time_per_epoch:  44.47944784164429\n",
      "time left:  0:01:26.794713\n",
      "num_epochs:  99\n",
      "time_per_epoch:  44.60456466674805\n",
      "time left:  0:00:43.409429\n",
      "Model saved in file: model-100x100-4glimpse-12x12-4scales-256batch-100epochs.ckpt\n",
      "time:  4349.222271203995\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.initialize_all_variables())\n",
    "  writer = tf.summary.FileWriter(logdir=tfLogFile, graph=tf.get_default_graph())\n",
    "  start___time = time.time()\n",
    "  for epoch in xrange(num_epochs):\n",
    "    print(\"num_epochs: \",epoch)\n",
    "    start_epoch = time.time()\n",
    "  \n",
    "    num_batches = x_train.shape[0] // config.batch_size\n",
    "    num_samples = num_batches * config.batch_size\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "      start = batch * config.batch_size\n",
    "      end = (batch + 1) * config.batch_size\n",
    "      images, labels = x_train[start:end], y_train[start:end]\n",
    "\n",
    "      loc_net.samping = True\n",
    "      avg_acc_val, softmax_val, adv_val, baselines_val, rewards_val, baselines_mse_val, xent_val, logllratio_val, \\\n",
    "          reward_val, loss_val, lr_val, _, summary_val = sess.run(\n",
    "              [avg_acc, softmax, advs, baselines, rewards, baselines_mse, xent, logllratio,\n",
    "               reward, loss, learning_rate, train_op, summary_op],\n",
    "              feed_dict={\n",
    "                  images_ph: images,\n",
    "                  labels_ph: labels\n",
    "              })\n",
    "      writer.add_summary(summary_val, epoch * num_batches + batch)\n",
    "\n",
    "      avg_loss += loss_val / num_batches\n",
    "\n",
    "      if batch and batch % 100 == 0:\n",
    "        logging.info('epoch {}: batch: {}/{}'.format(epoch, batch, num_batches - 1))\n",
    "        logging.info('epoch {}: avg_accuracy: {}'.format(epoch, avg_acc_val))\n",
    "        logging.info('epoch {}: lr = {:3.6f}'.format(epoch, lr_val))\n",
    "        logging.info(\n",
    "            'epoch {}: reward = {:3.4f}\\tloss = {:3.4f}\\txent = {:3.4f}'.format(\n",
    "                epoch, reward_val, loss_val, xent_val))\n",
    "        logging.info('llratio = {:3.4f}\\tbaselines_mse = {:3.4f}'.format(\n",
    "            logllratio_val, baselines_mse_val))\n",
    "        logging.debug('baselines = {}\\trewards = {}'.format(baselines_val, rewards_val))\n",
    "\n",
    "    # if epoch and epoch % training_steps_per_epoch == 0:\n",
    "    if True: # print each epoch\n",
    "      # Evaluation\n",
    "      for dataset in [(x_va, y_va,'va')]:\n",
    "        num_batches = dataset[0].shape[0] // config.eval_batch_size\n",
    "        correct_cnt = 0\n",
    "        num_samples = num_batches * config.eval_batch_size\n",
    "        loc_net.sampling = True\n",
    "        for test_step in xrange(num_batches):\n",
    "          images, labels = dataset[0][test_step * config.eval_batch_size : (test_step+1) * config.eval_batch_size], dataset[1][test_step * config.eval_batch_size : (test_step+1) * config.eval_batch_size]\n",
    "\n",
    "          avg_y_pred_val = sess.run(avg_y_pred,\n",
    "                                 feed_dict={\n",
    "                                     images_ph: images,\n",
    "                                     labels_ph: labels\n",
    "                                 })\n",
    "\n",
    "          correct_cnt += np.sum(avg_y_pred_val == labels)\n",
    "        acc = correct_cnt / num_samples\n",
    "\n",
    "        logging.info('epoch {}: valid_accuracy = {}'.format(epoch, acc))\n",
    "    \n",
    "    print(\"time_per_epoch: \",str(time.time() - start_epoch) )\n",
    "    logging.info('time_per_epoch: {}'.format(time.time() - start_epoch))\n",
    "    print(\"time left: \",str(datetime.timedelta(seconds=(time.time() - start___time)/(1+epoch) * (num_epochs-epoch) )))\n",
    "  logging.info('Training_time = {}'.format(time.time() - start___time))\n",
    "  for dataset in [(x_test, y_test, 'test')]:\n",
    "    num_batches = dataset[0].shape[0] // config.eval_batch_size\n",
    "    correct_cnt = 0\n",
    "    num_samples = num_batches * config.eval_batch_size\n",
    "    loc_net.sampling = True\n",
    "    for test_step in xrange(num_batches):\n",
    "      images, labels = dataset[0][test_step * config.eval_batch_size: (test_step + 1) * config.eval_batch_size], \\\n",
    "                       dataset[1][test_step * config.eval_batch_size: (test_step + 1) * config.eval_batch_size]\n",
    "\n",
    "      avg_y_pred_val = sess.run(avg_y_pred,\n",
    "                                feed_dict={\n",
    "                                  images_ph: images,\n",
    "                                  labels_ph: labels\n",
    "                                })\n",
    "\n",
    "      correct_cnt += np.sum(avg_y_pred_val == labels)\n",
    "    acc = correct_cnt / num_samples\n",
    "    logging.info('test_accuracy = {}'.format(acc))\n",
    "    \n",
    "  save_path = saver.save(sess, savedModel_path)\n",
    "  logging.info('Model saved in file: {}'.format(save_path))\n",
    "  print('Model saved in file: {}'.format(save_path))\n",
    "  logging.info('total time = {}'.format(time.time() - start___time))\n",
    "  print(\"time: \",time.time() - start___time)\n",
    "  \n",
    "  value = str(str(local_device_protos))\n",
    "  text_tensor = tf.make_tensor_proto(value, dtype=tf.string)\n",
    "  meta = tf.SummaryMetadata()\n",
    "  meta.plugin_data.plugin_name = \"text\"\n",
    "  summary = tf.Summary()\n",
    "  summary.value.add(tag=\"gpu_tag\", metadata=meta, tensor=text_tensor)\n",
    "  writer.add_summary(summary)\n",
    "  logging.info('gpu = {}'.format(str(local_device_protos)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: model-100x100-4glimpse-12x12-4scales-256batch-100epochs.ckpt\n"
     ]
    }
   ],
   "source": [
    "  print('Model saved in file: {}'.format(save_path))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ram.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensor-env] *",
   "language": "python",
   "name": "conda-env-tensor-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
